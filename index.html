<head>
	<title>Self-Supervised Policy Adaptation during Deployment</title>
	<meta property="og:title" content="Self-Supervised Policy Adaptation during Deployment">
	<meta property="og:description" content="Anonymized website for the PAD method for generalization in RL.">
	<meta property="og:image" content="method.png">
	<meta property="og:url" content="https://gtJZio9kuey3bL2Qn2426DvquU6Y4wQM.github.io/ICLR2021_Anonymized_PAD/">
	<meta name="twitter:card" content="summary_large_image">
	<style>
body {background-color: #fdfdfd; color: rgb(33, 37, 41); margin: 0;}
h1, h2, h3, h4, h5 {text-align: center;}
h1 {margin-bottom: 32px; font-size: 2.2em; }
h2 {margin-top: 48px;}
h1, h2, h3, h4, h5, a, p, span, body {font-weight: normal; font-family: sans-serif;}
.header {background-color: #f4f4f8; width: 100%; padding-top: 48px; padding-bottom: 32px;}
.content {max-width: 900px; margin: auto; margin-top: 48px;}
a {color: #2471a3; text-decoration: none;}
a:hover {color: #5499c7;}
.nobreak {white-space: nowrap;}
.hr {width: 100%; height: 1px; margin: 48px 0; background-color: #d6dbdf;}
p {line-height: 1.4em; text-align: justify;}
.abstract {max-width: 664px; margin: auto;}
.math {font-family: "Computer Modern Sans", sans-serif; font-style: italic;}
sub, sup {line-height: 0;}
.figure {width: 100%; min-height: 120px; margin: 36px 0; background-repeat: no-repeat; background-position: center; background-size: contain;}
.youtube {position: relative;}
.youtube iframe {margin: auto; display: block; margin-top: 48px;}
.content-video {width: 100%; margin: 0; text-align: center;}
.content-video-container {width: 100%; max-width: 900px; margin: auto;}
.legend {display: inline-block; border: 1px solid #eaeaea; padding: 8px; margin-top: 12px; text-align: center;}
.legend-item {display: inline-block; margin-left: 6px; margin-right: 6px; font-size: 12px;}
.legend-symbol {font-weight: bold; margin-right: 6px; font-size: 20px;}
.page {display: inline-block; width: 80px; height: 110px; border: 1px solid #bbb; margin: 2px; background-repeat: no-repeat; background-position: center; background-size: contain;}
table.authors {width: 100%; max-width: 700px; margin: auto; margin-bottom: 16px; text-align: center;}
table.authors a {padding: 6px 0; display: block;}
a.btn {display: inline-block; min-width: 70px; font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif, "Computer Modern Sans", sans-serif; background-color:  #2980b9; color: white; padding: 8px 18px; font-size: 0.9em; font-weight: normal; }
a.btn:hover {background-color:  #7fb3d5;}
a.btn-left {border-radius: 6px 0 0 6px;}
a.btn-right {border-radius: 0 6px 6px 0;}
.btn-bg-alt {background-color: #5499c7 !important;}
.btn-bg-alt:hover {background-color: #2471a3 !important;}
.bibtexsection {padding: 4px 16px; font-family: "Courier", monospace; font-size: 12px; white-space: pre; background-color: #f4f4f4; text-align: left;}
.noselect {-webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none;}
.bold {font-weight: bold;}
.italic {font-style: italic;}
div.spacing {width: 100%; height: 80px;}
	</style>
</head>

<div class="header">
	<h1>Self-Supervised Policy Adaptation<br/>during Deployment</h1>
	<table class="authors">
		<tbody>
			<tr>
				<td>
					<h4>
						<a href="#" class="nobreak">Anonymous authors</a>
					</h4>
				</td>
			</tr>
		</tbody>
	</table>
</div>
<div class="content">
	<div class="figure" style="height: 200px; background-image: url(method.png);"></div>
	<div class="hr"></div>
	<div>
		<h2>Abstract</h2>
		<p class="abstract">
			In most real world scenarios, a policy trained by reinforcement learning in one environment needs to be deployed in another, potentially quite different environment. However, generalization across different environments is known to be hard. A natural solution would be to keep training after deployment in the new environment, but this cannot be done if the new environment offers no reward signal. Our work explores the use of self-supervision to allow the policy to continue training after deployment without using any rewards. While previous methods explicitly anticipate changes in the new environment, we assume no prior knowledge of those changes yet still obtain significant improvements. Empirical evaluations are performed on diverse simulation environments from DeepMind Control suite and ViZDoom, as well as real robotic manipulation tasks in continuously changing environments, taking observations from an uncalibrated camera. Our method improves generalization in 28 out of 32 environments across various tasks and outperforms domain randomization on a majority of environments.
		</p>
	</div>
	<div class="hr"></div>
	<div>
		<video width="100%" controls>
			<source src="overview.mp4" type="video/mp4"/>
		</video>
	</div>
	<div class="hr"></div>
	<div>
		<h2>Non-stationary environments</h2>
		<p>
			We evaluate on a collection of natural video backgrounds and show that Policy Adaptation during Deployment (PAD) continuously adapts to changes in the environment. We here compare our method to the non-adaptive SAC trained with an inverse dynamics model (denoted <span class="italic">SAC+IDM</span>), as well as <a href="https://arxiv.org/abs/2004.04136">CURL (Srinivas et al.)</a>, a recently proposed contrastive method.
		</p>
		<div class="content-video">
			<div class="content-video-container">
				<video playsinline="" autoplay="" loop="" preload="" muted="" width="100%">
					<source src="non_stationary_experiments_25s.mp4" type="video/mp4"/>
				</video>
			</div>
			<div class="legend">
				<div class="legend-item">
					<span class="legend-symbol noselect" style="color: rgba(44,160,44,0.75)">--</span><span class="legend-symbol" style="color: rgba(214,39,40,0.75)">--</span><span class="legend-symbol" style="color: rgba(31,119,180,0.75)">--</span>SAC+IDM
				</div>
				<div class="legend-item">
					<span class="legend-symbol noselect" style="color: rgba(186,176,172,0.75)">--</span>CURL (Srinivas et al.)
				</div>
				<div class="legend-item">
					<span class="legend-symbol noselect" style="color: rgba(44,160,44,1)">—</span><span class="legend-symbol" style="color: rgba(214,39,40,1)">—</span><span class="legend-symbol" style="color: rgba(31,119,180,1)">—</span><span class="bold">SAC+IDM (PAD)</span>
				</div>
			</div>
		</div>
	</div>
	<div class="hr"></div>
	<div>
		<h2>Stationary environments</h2>
		<p>
			We evaluate on randomized environments and show that Policy Adaptation during Deployment (PAD) outperforms both <a href="https://arxiv.org/abs/2004.04136">CURL (Srinivas et al.)</a> and the non-adaptive SAC trained with an inverse dynamics model (denoted <span class="italic">SAC+IDM</span>) on a majority of tasks while impacting performance in the original (training) environment minimally.
		</p>
		<div class="content-video" style="margin-bottom: 32px">
			<div class="content-video-container">
				<video playsinline="" autoplay="" loop="" preload="" muted="" width="100%">
					<source src="stationary_experiments_10s.mp4" type="video/mp4"/>
				</video>
			</div>
			<div class="legend">
				<div class="legend-item">
					<span class="legend-symbol noselect" style="color: rgba(44,160,44,0.75)">--</span><span class="legend-symbol" style="color: rgba(214,39,40,0.75)">--</span><span class="legend-symbol" style="color: rgba(31,119,180,0.75)">--</span>SAC+IDM
				</div>
				<div class="legend-item">
					<span class="legend-symbol noselect" style="color: rgba(186,176,172,0.75)">--</span>CURL (Srinivas et al.)
				</div>
				<div class="legend-item">
					<span class="legend-symbol noselect" style="color: rgba(44,160,44,1)">—</span><span class="legend-symbol" style="color: rgba(214,39,40,1)">—</span><span class="legend-symbol" style="color: rgba(31,119,180,1)">—</span><span class="bold">SAC+IDM (PAD)</span>
				</div>
			</div>
		</div>
	</div>
	<div class="hr"></div>
	<div>
		<h2>Robotic manipulation</h2>
		<p>
			We train policies in simulation and deploy on a real robot, operating solely from an uncalibrated camera. PAD transfers successfully and can adapt to a variety of real-world environments, including environmental changes such as table cloths and disco lights.
		</p>
		<div class="content-video">
			<h3 class="bold" style="margin-top: 48px;">Reach</h3>
			<div class="content-video-container">
				<video playsinline="" autoplay="" loop="" preload="" muted="" width="60%">
					<source src="reach.mp4" type="video/mp4"/>
				</video>
			</div>
		</div>
		<div class="content-video">
			<h3 class="bold" style="margin-top: 48px;">Push</h3>
			<div class="content-video-container">
				<video playsinline="" autoplay="" loop="" preload="" muted="" width="60%">
					<source src="push.mp4" type="video/mp4"/>
				</video>
			</div>
		</div>
	</div>
	<div class="spacing"></div>
</div>
